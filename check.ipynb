{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutError",
     "evalue": "timed out",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTimeoutError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m triton_url = \u001b[33m\"\u001b[39m\u001b[33mlocalhost:8000\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m client = httpclient.InferenceServerClient(url=triton_url)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_model_ready\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrecognition\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRecognition model is READY!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yakhyo\\miniconda3\\envs\\torch\\Lib\\site-packages\\tritonclient\\http\\_client.py:441\u001b[39m, in \u001b[36mInferenceServerClient.is_model_ready\u001b[39m\u001b[34m(self, model_name, model_version, headers, query_params)\u001b[39m\n\u001b[32m    438\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    439\u001b[39m     request_uri = \u001b[33m\"\u001b[39m\u001b[33mv2/models/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m/ready\u001b[39m\u001b[33m\"\u001b[39m.format(quote(model_name))\n\u001b[32m--> \u001b[39m\u001b[32m441\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest_uri\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_params\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response.status_code == \u001b[32m200\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yakhyo\\miniconda3\\envs\\torch\\Lib\\site-packages\\tritonclient\\http\\_client.py:250\u001b[39m, in \u001b[36mInferenceServerClient._get\u001b[39m\u001b[34m(self, request_uri, headers, query_params)\u001b[39m\n\u001b[32m    247\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGET \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, headers \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(request_uri, headers))\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m headers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_stub\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    252\u001b[39m     response = \u001b[38;5;28mself\u001b[39m._client_stub.get(request_uri)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yakhyo\\miniconda3\\envs\\torch\\Lib\\site-packages\\geventhttpclient\\client.py:271\u001b[39m, in \u001b[36mHTTPClient.get\u001b[39m\u001b[34m(self, request_uri, headers)\u001b[39m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, request_uri, headers={}):\n\u001b[32m--> \u001b[39m\u001b[32m271\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMETHOD_GET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yakhyo\\miniconda3\\envs\\torch\\Lib\\site-packages\\geventhttpclient\\client.py:253\u001b[39m, in \u001b[36mHTTPClient.request\u001b[39m\u001b[34m(self, method, request_uri, body, headers)\u001b[39m\n\u001b[32m    250\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     response = \u001b[43mHTTPSocketPoolResponse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders_type\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mheaders_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPConnectionClosed \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    261\u001b[39m     \u001b[38;5;66;03m# connection is released by the response itself\u001b[39;00m\n\u001b[32m    262\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attempts_left > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yakhyo\\miniconda3\\envs\\torch\\Lib\\site-packages\\geventhttpclient\\response.py:269\u001b[39m, in \u001b[36mHTTPSocketPoolResponse.__init__\u001b[39m\u001b[34m(self, sock, pool, **kw)\u001b[39m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, pool, **kw):\n\u001b[32m    268\u001b[39m     \u001b[38;5;28mself\u001b[39m._pool = pool\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yakhyo\\miniconda3\\envs\\torch\\Lib\\site-packages\\geventhttpclient\\response.py:146\u001b[39m, in \u001b[36mHTTPSocketResponse.__init__\u001b[39m\u001b[34m(self, sock, block_size, method, headers_type, **kw)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;28mself\u001b[39m._sock = sock\n\u001b[32m    145\u001b[39m \u001b[38;5;28mself\u001b[39m.block_size = block_size\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yakhyo\\miniconda3\\envs\\torch\\Lib\\site-packages\\geventhttpclient\\response.py:166\u001b[39m, in \u001b[36mHTTPSocketResponse._read_headers\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.headers_complete:\n\u001b[32m    165\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    167\u001b[39m         \u001b[38;5;28mself\u001b[39m.feed(data)\n\u001b[32m    168\u001b[39m         \u001b[38;5;66;03m# depending on gevent version we get a conn reset or no data\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yakhyo\\miniconda3\\envs\\torch\\Lib\\site-packages\\gevent\\_socketcommon.py:662\u001b[39m, in \u001b[36mSocketMixin.recv\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    660\u001b[39m     \u001b[38;5;66;03m# QQQ without clearing exc_info test__refcount.test_clean_exit fails\u001b[39;00m\n\u001b[32m    661\u001b[39m     exc_clear() \u001b[38;5;66;03m# Python 2\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m662\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_event\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc\\\\gevent\\\\_hub_primitives.py:317\u001b[39m, in \u001b[36mgevent._gevent_c_hub_primitives.wait_on_socket\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc\\\\gevent\\\\_hub_primitives.py:322\u001b[39m, in \u001b[36mgevent._gevent_c_hub_primitives.wait_on_socket\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc\\\\gevent\\\\_hub_primitives.py:313\u001b[39m, in \u001b[36mgevent._gevent_c_hub_primitives._primitive_wait\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc\\\\gevent\\\\_hub_primitives.py:314\u001b[39m, in \u001b[36mgevent._gevent_c_hub_primitives._primitive_wait\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc\\\\gevent\\\\_hub_primitives.py:46\u001b[39m, in \u001b[36mgevent._gevent_c_hub_primitives.WaitOperationsGreenlet.wait\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc\\\\gevent\\\\_hub_primitives.py:46\u001b[39m, in \u001b[36mgevent._gevent_c_hub_primitives.WaitOperationsGreenlet.wait\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc\\\\gevent\\\\_hub_primitives.py:55\u001b[39m, in \u001b[36mgevent._gevent_c_hub_primitives.WaitOperationsGreenlet.wait\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc\\\\gevent\\\\_waiter.py:154\u001b[39m, in \u001b[36mgevent._gevent_c_waiter.Waiter.get\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc\\\\gevent\\\\_greenlet_primitives.py:61\u001b[39m, in \u001b[36mgevent._gevent_c_greenlet_primitives.SwitchOutGreenletWithLoop.switch\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc\\\\gevent\\\\_greenlet_primitives.py:61\u001b[39m, in \u001b[36mgevent._gevent_c_greenlet_primitives.SwitchOutGreenletWithLoop.switch\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc\\\\gevent\\\\_greenlet_primitives.py:65\u001b[39m, in \u001b[36mgevent._gevent_c_greenlet_primitives.SwitchOutGreenletWithLoop.switch\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc\\\\gevent\\\\_gevent_c_greenlet_primitives.pxd:35\u001b[39m, in \u001b[36mgevent._gevent_c_greenlet_primitives._greenlet_switch\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mTimeoutError\u001b[39m: timed out"
     ]
    }
   ],
   "source": [
    "import tritonclient.http as httpclient\n",
    "\n",
    "triton_url = \"localhost:8000\"\n",
    "client = httpclient.InferenceServerClient(url=triton_url)\n",
    "\n",
    "if client.is_model_ready(\"recognition\"):\n",
    "    print(\"Recognition model is READY!\")\n",
    "else:\n",
    "    print(\"Recognition model is NOT READY!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Outputs:\n",
      "Name: output, Shape: [0, 512]\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "onnx_model = onnx.load(\"models/recognition/1/model.onnx\")\n",
    "\n",
    "print(\"\\nModel Outputs:\")\n",
    "for output in onnx_model.graph.output:\n",
    "    print(f\"Name: {output.name}, Shape: {[dim.dim_value for dim in output.type.tensor_type.shape.dim]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Success: (1, 512)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tritonclient.http as httpclient\n",
    "\n",
    "TRITON_SERVER_URL = \"127.0.0.1:8000\"\n",
    "client = httpclient.InferenceServerClient(url=TRITON_SERVER_URL)\n",
    "\n",
    "# Test if the model is ready\n",
    "if not client.is_model_ready(\"recognition\"):\n",
    "    raise RuntimeError(\"Triton model 'recognition' is not ready!\")\n",
    "\n",
    "# Create a dummy input\n",
    "input_data = np.random.rand(1, 3, 112, 112).astype(np.float32)\n",
    "\n",
    "# Create input tensor\n",
    "inputs = httpclient.InferInput(\"input\", input_data.shape, \"FP32\")\n",
    "inputs.set_data_from_numpy(input_data)\n",
    "\n",
    "# Request output tensor\n",
    "outputs = [httpclient.InferRequestedOutput(\"output\")]\n",
    "\n",
    "# Perform inference\n",
    "response = client.infer(model_name=\"recognition\", inputs=[inputs], outputs=outputs)\n",
    "output_data = response.as_numpy(\"output\")\n",
    "\n",
    "print(\"Inference Success:\", output_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
